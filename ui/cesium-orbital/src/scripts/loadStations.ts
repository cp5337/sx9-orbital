/**
 * Load Ground Stations into Supabase
 *
 * Reads from data/selected_247_smart.json (curated station list)
 * Run with: npx tsx src/scripts/loadStations.ts
 *
 * IMPORTANT: The source JSON should only contain real stations with proper names.
 * Do NOT add auto-generated T1/T2 stations (e.g., "NorthAmerica-T1-001") - these
 * were a one-time database artifact from Oct 2025 with random ocean coordinates.
 * They were cleaned from all_ground_nodes_backup.json and selected_247_smart.json
 * on 2026-02-03.
 *
 * Valid sources: CableLanding, FinancialInfra, Equinix, IXP, LaserLight, xAI
 */

import { createClient } from '@supabase/supabase-js';
import * as fs from 'fs';
import * as dotenv from 'dotenv';
import { fileURLToPath } from 'url';
import { dirname, resolve } from 'path';

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

dotenv.config({ path: resolve(__dirname, '../../.env') });

const supabaseUrl = process.env.VITE_SUPABASE_URL;
const supabaseAnonKey = process.env.VITE_SUPABASE_ANON_KEY;
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY;

if (!supabaseUrl || !supabaseAnonKey) {
  throw new Error('Missing Supabase environment variables');
}

// Use service key for admin operations (delete), anon key for inserts
const supabase = createClient(supabaseUrl, supabaseAnonKey);
const supabaseAdmin = supabaseServiceKey
  ? createClient(supabaseUrl, supabaseServiceKey)
  : null;

interface SmartStation {
  id: string;
  name: string;
  city?: string;
  state?: string;
  country?: string;
  latitude: number;
  longitude: number;
  tier: number;
  zone: string;
  source: string;
  priority?: number;
  capacity_mw?: number;
  cable_systems?: string[];
  demand_gbps?: number;
  weather_score?: number;
}

interface SmartStationsFile {
  metadata: {
    total: number;
    description: string;
  };
  summary: Record<string, unknown>;
  selected: SmartStation[];
}

async function loadStations() {
  console.log('ðŸ“¡ Loading 247 Ground Stations into Supabase...\n');

  // Read the newest JSON file (corrected lat/long)
  const dataPath = resolve(__dirname, '../../../../data/selected_247_smart.json');
  console.log(`Reading from: ${dataPath}`);

  if (!fs.existsSync(dataPath)) {
    console.error('âŒ File not found:', dataPath);
    process.exit(1);
  }

  const rawData = fs.readFileSync(dataPath, 'utf-8');
  const data: SmartStationsFile = JSON.parse(rawData);

  // Filter out any auto-generated T1/T2 stations (should not exist, but safety check)
  const t1t2Pattern = /T[12]-\d+$/;
  const autoGenerated = data.selected.filter(s => t1t2Pattern.test(s.name));
  if (autoGenerated.length > 0) {
    console.warn(`âš ï¸  Filtering ${autoGenerated.length} auto-generated T1/T2 stations`);
    console.warn('   These should be removed from the source JSON');
    data.selected = data.selected.filter(s => !t1t2Pattern.test(s.name));
  }

  console.log(`Found ${data.selected.length} stations`);
  console.log(`Description: ${data.metadata.description}\n`);

  // Clear existing ground nodes (use admin client to bypass RLS if available)
  console.log('ðŸ—‘ï¸  Clearing existing ground_nodes...');
  const deleteClient = supabaseAdmin || supabase;
  if (supabaseAdmin) {
    console.log('   Using service role key for delete (bypasses RLS)');
  }
  const { error: deleteError } = await deleteClient
    .from('ground_nodes')
    .delete()
    .neq('id', '00000000-0000-0000-0000-000000000000');

  if (deleteError) {
    console.warn('Warning clearing table:', deleteError.message);
    if (!supabaseAdmin) {
      console.warn('   Tip: Add SUPABASE_SERVICE_ROLE_KEY to .env to bypass RLS');
    }
  }

  // Check if new columns exist
  const { error: schemaError } = await supabase
    .from('ground_nodes')
    .select('station_code')
    .limit(1);

  const hasNewColumns = !schemaError;
  if (hasNewColumns) {
    console.log('âœ… New columns exist (station_code, city, zone, source)');
  } else {
    console.log('âš ï¸  New columns not found - loading with basic schema only');
    console.log('   Run the SQL migration to add: station_code, city, country, zone, source');
  }

  // Transform to ground_nodes format
  // Let Supabase auto-generate UUID - use station.id as station_code for reference
  const groundNodes = data.selected.map((station) => {
    // Convert tier: 0 = highest priority -> tier 1, higher numbers -> tier 2/3
    const tier = station.tier <= 0 ? 1 : station.tier <= 1 ? 2 : 3;

    // Estimate demand based on source type
    const demandMap: Record<string, number> = {
      'FinancialInfra': 100,
      'Equinix': 80,
      'IXP': 60,
      'LaserLight': 90,
      'xAI': 95,
      'CableLanding': 50,
      'GroundNode': 40,
    };
    const demand = station.demand_gbps || demandMap[station.source] || 50;

    // Estimate weather score (can be refined with actual weather API)
    const weather = station.weather_score || 0.85;

    // Build name with station code prefix for readability in basic schema
    const displayName = hasNewColumns
      ? station.name
      : `[${station.id}] ${station.name}`;

    const baseFields = {
      // Omit id - let Supabase gen_random_uuid() handle it
      name: displayName,
      latitude: station.latitude,
      longitude: station.longitude,
      tier: tier as 1 | 2 | 3,
      demand_gbps: demand,
      weather_score: weather,
      status: 'active' as const,
    };

    // Add extended fields only if schema supports them
    if (hasNewColumns) {
      return {
        ...baseFields,
        station_code: station.id,        // Human-readable code like "NYSE-MAHWAH"
        city: station.city || null,
        country: station.country || null,
        zone: station.zone,              // Americas, EMEA, APAC
        source: station.source,          // CableLanding, FinancialInfra, etc.
      };
    }

    return baseFields;
  });

  // Insert in batches of 50
  const batchSize = 50;
  let inserted = 0;
  let errors = 0;

  for (let i = 0; i < groundNodes.length; i += batchSize) {
    const batch = groundNodes.slice(i, i + batchSize);

    const { data: insertedData, error: insertError } = await supabase
      .from('ground_nodes')
      .insert(batch)
      .select();

    if (insertError) {
      console.error(`\nâŒ Batch ${Math.floor(i / batchSize) + 1}:`, insertError.message);
      errors += batch.length;
    } else {
      inserted += insertedData?.length || 0;
      process.stdout.write(`\râœ… Inserted ${inserted}/${groundNodes.length} stations...`);
    }
  }

  console.log('\n');

  // Verify count
  const { count } = await supabase
    .from('ground_nodes')
    .select('*', { count: 'exact', head: true });

  // Summary
  console.log('=== Load Complete ===');
  console.log(`ðŸ“Š Total in file: ${data.selected.length}`);
  console.log(`âœ… Inserted: ${inserted}`);
  console.log(`âŒ Errors: ${errors}`);
  console.log(`ðŸ”¢ Verified in DB: ${count}`);

  // Distribution by source
  const sourceCounts = data.selected.reduce((acc, node) => {
    acc[node.source] = (acc[node.source] || 0) + 1;
    return acc;
  }, {} as Record<string, number>);

  console.log('\nðŸ“ Distribution by source:');
  Object.entries(sourceCounts)
    .sort((a, b) => b[1] - a[1])
    .forEach(([source, count]) => {
      console.log(`   ${source}: ${count}`);
    });

  // Distribution by zone
  const zoneCounts = data.selected.reduce((acc, node) => {
    acc[node.zone] = (acc[node.zone] || 0) + 1;
    return acc;
  }, {} as Record<string, number>);

  console.log('\nðŸŒ Distribution by zone:');
  Object.entries(zoneCounts).forEach(([zone, count]) => {
    console.log(`   ${zone}: ${count}`);
  });
}

loadStations().catch(console.error);
